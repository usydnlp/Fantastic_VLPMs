# Fantastic VLPMs
This repository contains a list of papers (codes if available) and pretraining/downstream task datasets for VLPMs, currently with main focus on *Text* and *Image*. If you find any error or have any suggestion, please don't hesitate to open an issue and contact us.

If you find this repository helpful for your research or work, please kindly cite our related survey paper as follows. The Bibtex are listed below:

```
@article{long2022vision,
  title={Vision-and-Language Pretrained Models: A Survey},
  author={Long, Siqu and Cao, Feiqi and Han, Soyeon Caren and Yang, Haiqing},
  journal={arXiv preprint arXiv:2204.07356},
  year={2022}
}
```
